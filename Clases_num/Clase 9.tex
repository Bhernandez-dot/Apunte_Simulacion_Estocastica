\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}


%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{tikz,pgfplots}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{dsfont}
\usepackage{cancel}
\usepackage{tikz,tkz-base,tkz-fct}
\usepackage{pgfplots}
\newcommand{\prob}{\mathbb{P}}
\newtheorem{definicion}{Definición}
\newtheorem{teorema}{Teorema}
\newtheorem{ejemplo}{Ejemplo}
\DeclareMathOperator*{\argmax}{Arg\,max}
\newtheorem{lem}{Lema}
\newtheorem{prop}{Proposici\'on}
\newtheorem{cor}{Corolario}
\newtheorem{dem}{Demostración}
\numberwithin{equation}{subsection}
\numberwithin{definicion}{subsection}
\newtheorem{obs}{Observación}


%% Aquí se pueden definir nuevas abreviaturas para algunos comandos

\def\sen{{\rm sen\mspace{1.5mu}}}
\def\C{\mathbb C}
\def\R{\mathbb R}
\def\N{\mathbb N}
\def\Q{\mathbb Q}
\def\Z{\mathbb Z}
\def\V{\mathbb V}
\def\E{\mathbb E}
\def\to{\rightarrow}
\newcommand{\pb}{\mathbb{P}}



\newcommand{\ds}{\displaystyle}


%Para hacer normas en tex

\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\normm}[1]{\bigg\lVert#1\bigg\rVert}


%integrales bacanes
\usepackage{ esint }

%Para poner en negrita en modo matemático
\newcommand{\negri}{\boldsymbol}




\title{Simulación Estocástica}
\author{Clase 9}
\date{20 de agosto de 2019}

\begin{document}
\maketitle

\subsubsection{Variables antitéticas}
Supongamos que deseamos calcular la siguiente integral;
\[I =   \int_{0}^1 f(x)dx\]
Dado que el cambio de variable: $x\rightarrow 1-x$ es invariante ante la medida $dx$ en $[0,1]$. Es decir,
\[\int_{0}^1f(x)dx = \int_{0}^1f(1-x)dx\]
Entonces es posible reescribir $I$ de la sigueinte forma:
\[I = \frac{1}{2}\int_{0}^1 (f(x) + f(1-x))dx\]
Otra forma de plantear el problema, es definir la variable aleatoria $X\sim unif(0,1)$. Así, $1-X \sim unif(0,1)$, entonces:
\[I = \E(f(X)) = \E\left(\frac{f(X)+f(1-X)}{2}\right)\]
y obtenemos la misma conclusión.\\ \newline

Ahora, podemos calcular $I$ con $M.M.C.$. Simulamos $n$ variables aleatorias $i.i.d.$ uniformes en $[0,1]$, $U_1,\cdots,U_n$, y aproximamos $I$ por:
\[I_{2n} = \frac{1}{n}\left(\frac{1}{2}(f(U_1)+f(1-U_1))+ \cdots + (f(U_n)+f(1-U_n))\right)\]
\[= \frac{1}{2n}(f(U_1)+f(1-U_1) + \cdots + f(U_n) + f(1-U_n))\]
A grandes razgos, este método es equivalente a emplear el método tradicional de Monte Carlo, con la variable $\frac{f(U)+f(1-U)}{2}$. Podemos observar que su varianza:
\[Var\left(\frac{f(U)+f(1-U)}{2}\right) = \frac{1}{4}Var\left(f(U) + f(1-U)\right)\]
\[= \frac{1}{4}\left(Var\left(f(U)\right) + 2Cov\left(f(U),f(1-U)\right) + Var\left(f(1-U)\right)\right)\]
Dado que $X\overset{d}{=}1-X$:
\[Var\left(\frac{f(U)+f(1-U)}{2}\right) = \frac{1}{2}\left[Var(f(U)) + Cov(f(U),f(1-U))\right]\]
Así, si $Cov(f(U),f(1-U)) \leq 0$, se reduce la varianza de la estimación en al menos un factor de 1/2.\\ \newline
En general, tenemos que la aproximación mejora siempre que:
\[\E\left(f(U)f(U-1)\right) < \E\left(f(U)^2\right)\]

\begin{lem} Si $f$ es una función \textit{monótona}, entonces:
\[Cov(f(U),f(1-U)) \leq0\]
\end{lem}
\subsubsection{Método de Estratificación}
Este mpetodo es bien conocido en el diseño de muestras de encuestas. Supongamos que se busca calcular
\[I = \E\left(g(X)\right) = \int g(x)f(x)dx\]
Donde $X$ tiene ley $f(x)dx$. Consideremos $D_1,\cdots,D_m$, una partición del soporte de la densidad $f$. Luego, podemos descomponer $I$ en
\begin{equation}
    I = \sum_{i=1}^m I_i = \sum_{i=1}^m \E\left(\mathbbm{1}_{\{X\in D_i\}}g(X)\right)
    \label{eq_estrat1}
\end{equation}

Este método propone estimar $I_i$ con $M.M.C.$, usando $n_i$ simulaciones. Definimos como $\sigma_i^2 = Var(\mathbbm{1}_{\{X\in D_i\}}g(X))$. Entonces, la varianza de la aproximación es

\begin{equation}
    \sum_{i=1}^m \frac{\sigma_i^2}{n_i}
    \label{eq_estrat2}
\end{equation}

Si minimizamos \ref{eq_estrat2}, bajo la restricción de un número de simulaciones $\sum_{i=1}^m n_i = n$ dado, obtenemos $n_i =n\sigma_i/\sum_{i=1}^m\sigma_i$, con un valor mínimo de la varianza de
\[\frac{\left(\sum_{i=1}^m \sigma_i\right)^2}{n}\]
Puede probarse que esta varianza es menor que la obtenida con $n$ simulaciones bajo el método estándar de Monte Carlo directamente en \ref{eq_estrat1}. Por supuesto, rara vez es posible calcular el valor de $\sigma_i$, lo que limita el uso de esta técnica (pero bien uno puede estimarlos vía su estimador insesgado de varianza mínima $\frac{1}{n-1}\sum (x_i-\Bar{x})^2$, o bajo el propio $M.M.C.$).

\section{Cadenas de Markov}
Una cadena de Markov es una sucesión de variables aleatorias $\left\{X_n;n=0,1,2,...\right\}$, definidas sobre algún espacio de probabilidad $\left(\Omega,\mathcal{
F}, \prob\right)$, tomando valores en un conjunto $E$ arbitrario, pero que supondremos que será finito o numerable, y que posee la propedad de Markov. Intuitívamente, una cadena de Markov posee la cualidad de que, conociendo el estado presente $X_n$, sin necesidad de conocer los estados anteriores puede hacer buenas predicciones acerca de los estados futuros.\\ Los siguientes temas presentan variadas aplicaciones de las cadenas de Markov. Tenga en cuenta que restringiremos el contenido a cadenas de Markov \textit{homogéneas}, aunque el caso no homogéneo sea necesario en muchas aplicaciones.

\subsection{Definiciones y propiedades elementales}

\begin{definicion}
Sea $E$ un conjunto finito o numerable. Un proceso estocástico $\{X_n;n\in \N\}$ es llamado \textit{Cadena de Markov} si, para todo $n\in\N$, la ley condicional de $X_{n+1}$ dado $X_0,X_1,\cdots,X_n$, es igual a la ley condicional de $X_{n+1}$ dado $X_n$.\\ \newline Esto es; $\forall\,x_0,\cdots,x_n\,\in E$:
\[\prob\left(X_{n+1}=x_{n+1}\,|\,X_o = x_0,\,X_1=x_1,\,\cdots,\,X_n=x_n\right) = \prob\left(X_{n+1}=x_{n+1}\,|\,X_n=x_n\right)\]
La cadena se dirá 'Homogénea', si lo anterior no depende del índice $n$. En cuyo caso, la matriz $P=\left(P_{xy}\right)_{x,y\in E}$, con $P_{x,y} = \prob\left(X_{n+1}=y\,|\,X_n = x\right)$\\ \newline
Además, llamamos $\mu\in \mathcal{P}(E)$ a $\mu_x = \prob(X_0 = x)$, denominada 'Distribución inicial'. Así, decimos que $\left(X_n\right)_{n\in\N}$ es una $(\mu,P)$-cadena de Markov homogénea.
\end{definicion}

\begin{ejemplo}
En $E=\Z$, si $Z_0,Z_1,Z_2,...$ son las ganancias de apuestas modeladas como variables aleatorias $i.i.d.$, entonces la ganancia total acumulada $X_n = \sum_{i=0}^nZ_i$ es una cadena de arkov ($C.M.$).
\end{ejemplo}

Un simple criterio, que nos permitirá en muchos casos verificar si un proceso dado es C.M., está dado por el siguiente lema.

\begin{lem}
Sean $E$ y $F$ dos conjuntos numerables, y sea $f$ un mapeo de $\N\times E \times F$ hacia $E$. Sean $X_0,Y_1,Y_2,...$, son variables aleatorias mútuamente independientes, siendo $X_0$ valor en $E$ e $Y_n$ valores en $F$.\\ 
Sean $\{X_n;\,n\geq 1\}$ un proceso en $E$, definido como:
\[X_{n+1} = f(n,X_n,Y_{n+1}),\hspace{0.7cm}n\in\N\]
Entonces $\{X_n;\,n\in\N\}$ es cadena de Markov.
\end{lem}

\textbf{Demostración: }
\[\prob\left(X_{n+1} = x_{n+1}\,|\,X_0=x_0,\,\cdots,\,X_n=x_n\right) = \frac{\prob\left(X_0=x_0,\,\cdots,\,X_n=x_n,\,X_{n+1}=x_{n+1}\right)}{\prob\left(X_0=x_0,\,\cdots,\,X_n=x_n\right)}\]
\[ = \sum_{\{z;f(n,x_n,z)=x_{n+1}\}}\frac{\prob\left(X_0=x_0,\,\cdots,\,X_n=x_n,\,Y_{n+1}=z\right)}{\prob\left(X_0=x_0,\,\cdots,\,X_n=x_n\right)}\]
Dado que $Y_{n+1}$ es una variable independiente a todos los valores $\{X_0,\cdots,X_n\}$, entonces:
\[ = \sum_{\{z;f(n,x_n,z)=x_{n+1}\}}\frac{\prob\left(X_0=x_0,\,\cdots,\,X_n=x_n,\,Y_{n+1}=z\right)}{\prob\left(X_0=x_0,\,\cdots,\,X_n=x_n\right)}\]
\[ = \sum_{\{z;f(n,x_n,z)=x_{n+1}\}}\frac{\prob\left(X_0=x_0,\,\cdots,\,X_n=x_n\right)\prob\left(Y_{n+1}=z\right)}{\prob\left(X_0=x_0,\,\cdots,\,X_n=x_n\right)}\]
\[ = \sum_{\{z;f(n,x_n,z)=x_{n+1}\}}\prob\left(Y_{n+1}=z\right)\]
\[=\frac{\prob\left(X_n = x_n,\,X_{n+1}=x_{n+1}\right)}{\prob\left(X_n =x_n\right)} = \prob\left(X_{n+1}=x_{n+1}\,|\,X_n=x_n\right)\]
\rule{0.7em}{0.7em}
\end{document}