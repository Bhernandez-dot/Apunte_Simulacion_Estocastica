\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}


%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{tikz,pgfplots}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{dsfont}
\usepackage{cancel}
\usepackage{tikz,tkz-base,tkz-fct}
\usepackage{pgfplots}
\newcommand{\prob}{\mathbb{P}}
\newtheorem{definicion}{Definición}
\newtheorem{teorema}{Teorema}
\newtheorem{ejemplo}{Ejemplo}
\DeclareMathOperator*{\argmax}{Arg\,max}
\newtheorem{lem}{Lema}
\newtheorem{prop}{Proposici\'on}
\newtheorem{cor}{Corolario}
\newtheorem{dem}{Demostración}
\numberwithin{equation}{subsection}
\numberwithin{definicion}{subsection}
\newtheorem{obs}{Observación}


%% Aquí se pueden definir nuevas abreviaturas para algunos comandos

\def\sen{{\rm sen\mspace{1.5mu}}}
\def\C{\mathbb C}
\def\R{\mathbb R}
\def\N{\mathbb N}
\def\Q{\mathbb Q}
\def\Z{\mathbb Z}
\def\V{\mathbb V}
\def\E{\mathbb E}
\def\to{\rightarrow}
\newcommand{\pb}{\mathbb{P}}



\newcommand{\ds}{\displaystyle}


%Para hacer normas en tex

\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\normm}[1]{\bigg\lVert#1\bigg\rVert}


%integrales bacanes
\usepackage{ esint }

%Para poner en negrita en modo matemático
\newcommand{\negri}{\boldsymbol}




\title{Simulación Estocástica}
\author{Clase 7}
\date{13 de agosto de 2019}

\begin{document}
\maketitle

\begin{enumerate}
    \item \textbf{Simulación de una variable aleatoria Bernoulli:} Sea $0<p<1$. Si $U$ es una variable aleatoria $unif(0,1)$. Entonces $X=\mathbbm{1}_{\{U \leq p\}}$ es una variable $Bernoulli$ de parámetro $p$.
    \item \textbf{Simulación de una variable aleatoria Binomial:} Sea $n\in\N$, $U_1,U_2,\cdots,U_n$ variables aleatorias $i.i.d.$ $unif(0,1)$, entonces:
    \[X=\mathbbm{1}_{\{U_1\leq p\}} + \mathbbm{1}_{\{U_2\leq p\}}+\cdots + \mathbbm{1}_{\{U_n \leq p\}}\]
    es una variable aleatoria binomial de parámetros $n$ y $p$, $B(n,p)$.
    \item \textbf{Simulación de una variable aleatoria Geométrica:}
    \[X = \inf\{k\geq 1;\,U_k\leq p\}\]
    Cuando $(U_n)_n$ son variables aleatorias $i.i.d.$ con distribución $unif(0,1)$, \\entonces $X\sim geom(p)$.
\end{enumerate}
Para proceder a una simulación más eficiente nos basaremos en el siguiente lema.

\begin{lem} Sea $X$ una vaiable aleatoria, y $F$ su función de distribución ($i.e.$ $F(x) = \pb(X\leq x)$). Para $0\leq t\leq 1$, definimos:
\[F^{-1}(t) = \inf\{x;\,F(x)>t\}\]
Entonces, si $U$ tiene ley $unif(0,1)$, $F^{-1}(U)$ tiene ley $\mathcal{L}(X)$.
\end{lem}

\textbf{Demostración: }Notemos que si $F$ es una función invertible, entonces su inversa coincide con $F^{-1}$, además tendremos que $F^{-1}$ será una función creciente, al igual que $F$. Entonces:
\[\pb(F^{-1}(U)\leq t) = \pb(U\leq F(t)) = \int_{0}^{F(t)}dx = F(t) = \pb(X\leq t)\]
Donde la integral sale del hecho de que $U$ es una variable uniforme entre $[0,1]$ y $F(t)$ siempre pertenece a tal intervalo por ser una probabilidad.\\ \newline
¿Qué pasa cuando la función $F$ no es invertible? Notemos que $\forall\,x\in\R$:
\begin{equation}
    \{t\,:\,F^{-1}(t)\leq x\}\,\cup\,\{F(x)\}\,=\,\{t\,:\,t\leq F(x)\}
    \label{eq.dem1MC}
\end{equation}
En efecto: claramente $F(x)\in\,\{t\,:\,t\leq F(x)\}$, además:
\[F^{-1}(t)\leq x\,\Longleftrightarrow\,\inf\{y\,:\,F(y)>t\}\leq x\,\Longleftrightarrow\,\exists y*\leq x,\,\exists y_n\searrow y*,\,t.q.\,F(y_n)>t\,\forall\,n\]
Dado que $F$ es una función de distribución, es contínua por la derecha, entonces $F(y*)\geq t$. Ocupando que $F$ es creciente, tenemos:
\[y*\leq x\,\wedge\,F(y*)\geq t\,\Rightarrow\,F(x)\geq F(y*)\geq t\]
Esto prueba la inclusión $\subseteq$ en \ref{eq.dem1MC}. Recíprocamente, si $F(x)\geq t$ hay dos casos posibles:
\begin{itemize}
    \item Si $t=F(x)$, entonces el lado izquierdo de \ref{eq.dem1MC} corresponde al síngleton.
    \item Si $t<F(x)$, por definición de ínfimo:
    \[x\geq \inf\{y\,:\,F(y)>t\} = F^{-1}(t)\]
    Por lo tanto $t$ pertenece al lado izquierdo de \ref{eq.dem1MC} y se concluye la segunda inclusión.
\end{itemize}
Entonces, usando \ref{eq.dem1MC}; sea $Y=F^{-1}(U)$:
\[\pb(Y\leq y) = \pb(F^{-1}(U)\leq y)\]
Como $U$ es una variable aleatoria absolutamente contínua los síngleton tienen medida de probabilidad igual a cero. Así:
\[\pb(F^{-1}(U)\leq y) = \pb(F^{-1}(U)\leq y\,\vee\,U=F(y))\, \overset{\ref{eq.dem1MC}}{=}\,\pb(U\leq F(y)) = F(y)\]
Luego la función de probabilidad acumulada de $Y$ es $F$, es decir $Y\sim \mathcal{L}(X)$. \rule{0.7em}{0.7em}\\ \newline
En los casos en que la función de distribución $F$ tiene inversa de forma explícita, el lema anterior nos permita, cómodamente, simular realizaciones de la variable $X$.

\begin{ejemplo}[variable aleatoria exponencial.] Para $X\sim exp(\lambda)$, $F(x)=1-e^{-\labda x}$ $\forall\,x\geq 0$, luego:
\[F^{-1}(t) = -\frac{log(1-t)}{\lambda}\]
Por el lema anterior; para $U\sim unif(0,1)$.
\[F^{-1}(U) = -\frac{log(1-U)}{\lambda}\,\sim\,exp(\lambda)\]
Finalmente, si $U\sim unif(0,1)$ entonces la variable aleatoria $1-U$ también es uniforme en el intervalo [0,1], por lo tanto:
\[F^{-1}(U)\,\overset{d}{=}\,-\frac{log(U)}{\lambda}\,\sim\,exp(\lambda)\]
\end{ejemplo}

Una de las variables más importantes de simular son las variables aleatorias normales. Lamentablemente, el lema anterior no nos es de utilidad pues no conocemos una forma explícita de la función de distribución, sin embargo podemos hacer lo siguiente.\\ Si $U,V\,\sim unif(0,1)$ independientes, entonces:
\[X:= \sqrt{-2log(U)}cos(2\pi V)\hspace{0.3cm},\hspace{0.3cm}Y:=\sqrt{-2log(U)}sin(s\pi V)\]
son variables aleatoria con distribución $\mathcal{N}(0,1)$ independientes (\textbf{ejercicio, cambio de variable}). Luego, para generar $\mathcal{N}(\mu,\sigma^2)$, basta ponderar y trasladar de la forma $\sigma X + \mu$.\footnote{Los software ocupan algoritmos de mayor eficiencia para generar variables aleatorias normales, por ejemplo el algoritmo de Ziggurat.}

\subsection{Método de Aceptación-Rechazo}
Supongamos que conocemos $X$, una variable aleatoria con función de densidad $f$ conocida, pero sin $F^{-1}$ explícita. El objetivo es poder simular realizaciones de $X$, ¿cómo podemos simular $X$?\\ Supongamos que existe $Y$, una variable aleatoria eficientemente simulable, con función de densidad $g$ que cumpla lo siguiente:
\[\exists\,k>0,\hspace{0.5cm}f(x)\leq kg(x)\,\,\forall\,x\]
\[g(x)>0\,\Longleftrightarrow\,f(x)>0\]
Entonces, $\forall\,x$ tal que $g(x)>0$, definimos:
\begin{equation}
    \alpha(x) = \frac{f(x)}{kg(x)}
    \label{eq.alpha de x}
\end{equation}

\begin{prop} Sean $(Y_n,U_n)_n$ una secuencia de realizaciones independientes, tal que $U_n\sim unif(0,1)$, $Y_n\,\overset{d}{=}\,Y$ y $U_n$ es independiente de $Y_n$ para todo $n$. Definimos la variable aleatoria $N$ como:
\[N=\inf\{k\in\N\,:\,U_k \leq \alpha(Y_k)\}\]
Entonces $N<\infty$ c.s. y $Y_N \,\overset{d}{=}\,X$.
\end{prop}

\textbf{Demostración: }Veamos que $N<\infty$ $\pb-c.s.$ Para ello, notemos que:
\[\pb(N=\infty) = \pb(\forall\,m\,,\,U_m>\alpha(Y_m)) = \lim_{n \to \infty}\pb(\forall\,m=1,\cdots,n\,:\,U_m>\alpha(Y_m))\]
Como las realizaciones son $i.i.d.$ tenemos que:
\[\lim_{n \to \infty}\pb(\forall\,m=1,\cdots,n\,:\,U_m>\alpha(Y_m)) = \lim_{n \to \infty}\left[\pb(U_m > \alpha(Y_m))\right]^{n} = 0\]
Donde la última igualdad sale de que $\pb(U>\alpha(Y)) < 1$ (con la desigualdad estricta.\\ \newline
En efecto, sea $p=\pb(U\leq \alpha(Y))$, usando probabilidades totales:
\[p = \pb(U\leq \alpha(Y)) = \int_{\R}\pb(U\leq \alpha(y))g(y)dy= \int_{\R}\left(\int_{0}^{\alpha(y)}dx\right)g(y)dy\]
\[=\int_{\R}\alpha(y)g(y)dy = \int_{\R}\frac{f(y)}{kg(y)}g(y)dy = \frac{1}{k}\int_{\R}f(y)dy = \frac{1}{k}\,>\,0\]
Como $p>0$,entonces $1-p = \pb(U>\alpha(Y))<1$ y concluímos que $N<\infty$ $\pb-c.s.$\\ \newline
Ahora veamos que $Y_N \,\overset{d}{=}\,X$. $\forall\,A\subseteq \mathcal{B}(\R)$ tenemos que:
\[\pb(Y_N \in A) = \sum_{n=1}^{\infty}\pb(Y_n \in A,\,N=n) = \sum_{n=1}^{\infty}\pb(Y_n \in A,\,U_n\leq\alpha(Y_n),\,U_m>\alpha(Y_m),\,\forall\,m=1,\cdots,n-1)\]
\[=\sum_{n=1}^{\infty}(1-p)^{n-1}\pb(Y_n \in A,\,U_n\leq \alpha(Y_n))\]\[= \sum_{n=1}^{\infty}(1-p)^{n-1} \int_{\R}\pb(y \in A,\,U_n\leq \alpha(y))g(y)dy\]
Recordando que $U_n$ es uniforme, y (por lo visto al principio de la demostración) $p=1/k$:
\[\pb(Y_N \in A)= \sum_{n=1}^{\infty}(1-p)^{n-1} \int_{\R}\pb(y \in A,\,U_n\leq \alpha(y))g(y)dy\]\[= \sum_{n=1}^{\infty}(1-p)^{n-1}\int_{\R}\mathbbm{1}_{y\in A}\alpha(y)g(y) dy\]
\[=\sum_{n=1}^{\infty}(1-p)^{n-1}\int_{\R}\mathbbm{1}_{y\in A}\frac{f(y)}{kg(y)}g(y) dy\] \[= \sum_{n=1}^{\infty}(1-p)^{n-1}p\int_{\R}\mathbbm{1}_{y\in A}f(y) dy\] \[= \pb(X \in A)\sum_{n=1}^{\infty}p(1-p)^{n-1}= \pb(X\in A)\] 
\rule{0.7em}{0.7em}
\end{document}