\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}


%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{tikz,pgfplots}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{dsfont}
\usepackage{cancel}
\usepackage{tikz,tkz-base,tkz-fct}
\usepackage{pgfplots}
\newcommand{\prob}{\mathbb{P}}
\newtheorem{definicion}{Definición}
\newtheorem{teorema}{Teorema}
\newtheorem{ejemplo}{Ejemplo}
\DeclareMathOperator*{\argmax}{Arg\,max}
\newtheorem{lem}{Lema}
\newtheorem{prop}{Proposici\'on}
\newtheorem{cor}{Corolario}
\newtheorem{dem}{Demostración}
\numberwithin{equation}{subsection}
\numberwithin{definicion}{subsection}
\newtheorem{obs}{Observación}


%% Aquí se pueden definir nuevas abreviaturas para algunos comandos

\def\sen{{\rm sen\mspace{1.5mu}}}
\def\C{\mathbb C}
\def\R{\mathbb R}
\def\N{\mathbb N}
\def\Q{\mathbb Q}
\def\Z{\mathbb Z}
\def\V{\mathbb V}
\def\E{\mathbb E}
\def\to{\rightarrow}
\newcommand{\pb}{\mathbb{P}}



\newcommand{\ds}{\displaystyle}


%Para hacer normas en tex

\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\normm}[1]{\bigg\lVert#1\bigg\rVert}


%integrales bacanes
\usepackage{ esint }

%Para poner en negrita en modo matemático
\newcommand{\negri}{\boldsymbol}




\title{Simulación Estocástica}
\author{Clase 13}
\date{03 de septiembre de 2019}

\begin{document}
\maketitle

\textbf{Observación: }Podemos definir el periodo del estado $x\in E$ como el máximo común divisor de los enteros $n$ tales que $(P^n)_{xx}>0$. Uno puede mostrar, con un argumento muy cercano al lema anterior, que cuando $P$ es reducible, todos los estados tienen el mismo periodo. Un estado se dice \textit{aperiódico} si su periodo es 1.\\ \newline
Ahora precisamos de la velocidad, o taza de convergencia del teorema anterior, bajo una supocisión adicional, llamada \textbf{condición de Doeblin}: existe $n_0\in \N$, $\beta>0$ y una probabilidad $\nu$ sobre $E$ tal que
\[(D)\hspace{1cm}(P^{n_0})_{xy}\geq \beta\nu_y,\hspace{0.2cm}\forall\,x,y\in E.\]
\textbf{Observación:} La condición $(D)$ es equivalente a la condición
\[\exists\,x\in E,\,n_0\geq 1\,\text{ tal que }\inf_{y\in E}(P^{n_0})_{yx} > 0.\]
Esto indica que el estado $x$ es aperiódico. Pero esto no implica la irreducibilidad. Queda como ejercicio mostrar que esto implica la existencia de una única clase recurrente y de una única probabilidad invariante.

\begin{lem}
Si $P$ es irreducible y aperiódica, y #E# es finito, entonces la condición $(D)$ se satisface.
\end{lem}

\textbf{Demostración: }Elegimos $x\in E$. Para cada $y\in E$, existe un $n_y$ tal que $n\geq n_y\,\Longrightarrow\, (P^n)_{yx}>0$. Sea
\[\Bar{n} = \sup_{y\in E}n_y,\hspace{0.3cm}\alpha = \inf_y (P^{\Bar{n}})_{yx}.\]
Entonces $\alpha >0$, y para todo $y\in E$,
\[(P^{\Bar{n}})_{yx}\geq \alpha.\]
Por lo tanto la condición $(D)$ se satisface con $n_0 = \Bar{n}$, $\beta=\alpha$, $\nu = \delta_x$.\\
\rule{0.7em}{0.7em}\\ \newline

Por otro lado, la condición de Doeblin es raramente satisfecha en el caso $|E| = +\infty$, dado que, típicamente, para todo $n\in \N$, $y\in E$,
\[\inf_{x\in E}(P^n)_{xy} = 0.\]

Para Obtener una taza de convergencia de $(P^n)_{xy}$ a $\pi_y$, necesitamos una forma de cuantificar esa convergencia.\\ Para ello utilizaremos la norma $l^1(\mathcal{P}(E))$ entre $\mu$ y $\nu$, medidas de probabilidad en $E$.\newline Por ejemplo,
\[||\mu-\nu ||_1 := \sum_{x\in E}|\mu_x - \nu_x|\]
Ahora introduciremos una herramienta que será de gran utilidad en las siguientes demostraciones.
\begin{definicion}
Un \textbf{coupling} de dos probabilidades $p$ y $q$ sobre $E$ es un par $(X,Y)$ de variables aleatorias a valores en $E$, tales que $p$ es la ley de $X$ y $q$ es la ley de $Y$.
\end{definicion}

\begin{lem}
Sean $p$ y $q$, dos probabilidades en $E$. 
\[||p-q||_1 = 2 \inf_{(X,Y)\,\text{coupling de }p,q}\prob(X\neq Y)\]
\end{lem}

\textbf{Demostración: }Primero, notemos que  si $(X,Y)$ es coupling de $p$ y $q$,
\[\prob(X=Y)=\sum_{x\in E}\prob(X=Y=x) \leq \sum_{x\in E}p_x\wedge q_x\]
Entonces,
\[\prob(X\neq Y)\geq 1- \sum_{x \in E}p_x\wedge q_x = \sum_{x\in E}(p_x-q_x)^{+}\]
y
\[||p-q||_1 = \sum_{x\in E}|p_x-q_x| \leq 2\prob(X\neq Y).\]
Por otro lado, definiendo $\alpha = \sum_{x \in E}p_x\wedge q_x$. Si $\xi, U,V$ y $W$ variables aleatorias mutuamente independientes tales que; $\xi \sim Bernoulli(\alpha)$, la ley de $U$ es $r$, definido por $r_x=\alpha^{-1}p_x\wedge q_x$, la ley de $V$ es $\Bar{p}$ definido por $\Bar{p}_x = (1-\alpha)^{-1}(p_x-q_x)^{+}$, y la ley de $W$, $\Bar{q}$, definida como $\Bar{q}_x = (1-\alpha)^{-1}(q_x-p_x)^{+}$, entonces 
\[X= \xi U + (1-\xi)V,\]
\[Y =\xi U +(1-\xi)W\]
es un coupling $(X,Y)$ de p y q.\\ En efecto, calculemos $\mathcal{L}(X)$:
\[\prob(X=x) = \prob(X=x\,|\,\xi=1)\prob(\xi = 1) + \prob(X=x\,|\,\xi=0)\prob(\xi=0)\]
\[= \prob(U=x)\prob(\xi = 1) + \prob(V=x)\prob(\xi=0)\]
\[= \frac{p_x\wedge q_x}{\alpha}\alpha + \frac{(p_x - q_x)^{+}}{1-\alpha}(1-\alpha)\]
\[= p_x\wedge q_x + (p_x -q_x)^{+} = p_x\]
Por lo tanto $\mathcal{L}(X) = p$. De la misma forma se muestra que $\mathcal{L}(Y) = q$.\\ \newline
Veamos que $\prob(X\neq Y) = (1-\alpha)$:
\[\prob(X\neq Y) = \prob(X\neq Y\,|\,\xi=1)\prob(\xi=1) + \prob(X\neq Y\,|\,\xi=0)\prob(xi=0)\]
\[= \cancel{\prob(U\neq U)}^{0}\prob(\xi=1) + \prob(V\neq W)\prob(\xi =0)\]
\[= \left[ 1-\prob(V=W)\right](1-\alpha)\]
\[= \left[1 - \sum_{x \in E}\prob(V=x,W=x)\right](1-\alpha)\]
\[= \left[1 - \sum_{x \in E}\prob(V=x)\prob(W=x)\right](1-\alpha)\]
\[=\left[ 1- \sum_{x\in E}\frac{(p_x -q_x)^{+}(q_x-p_x)^{+}}{(1-\alpha)^{2}}\right](1-\alpha)\]
\[=(1-\alpha)\]
De donde la última igualdad sale de que el producto $(p_x-q_x)^{+}(q_x-p_x)^{+} = 0$, $\forall\,x\in E$.\\ \newline
Luego, 
\[||p-q||_1 = \sum_{x\in E}|p_x-q_x| = \sum_{x\in E}[p_x+q_x-2(p_x\wedge q_x)]\]
\[= 2 - 2\sum_{x\in E}p_x\wedge q_x = 2-2\alpha = 2(1-\alpha) = 2\prob(X\neq Y).\]
\rule{0.7em}{0.7em}\\ \newline

\textbf{Observación: }Sea $(E,d)$ un espacio métrico cualquiera ($E$ no necesariamente inito o numerable), $\forall\,\mu,\nu$, probabilidades sobre $E$, poddemos definir
\[W_d(\mu,\nu) :=\inf_{\text{coupling de }\mu,\nu} \E\left[d(X,Y)\right]\]
Esto define una distancia sobre el espacio de medidas de probabilidad de $E$, llamada \textit{distancia de Wesserstein}. Notar que el caso en que la distancia del espacio sea $d(x,y)=\mathbbm{1}_{x\neq y}$, da lugar a $\E\left[d(x,y)\right] = \prob(X\neq Y)$.
\end{document}