\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}


%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{tikz,pgfplots}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{dsfont}
\usepackage{cancel}
\usepackage{tikz,tkz-base,tkz-fct}
\usepackage{pgfplots}
\newcommand{\prob}{\mathbb{P}}
\newtheorem{definicion}{Definición}
\newtheorem{teorema}{Teorema}
\newtheorem{ejemplo}{Ejemplo}
\DeclareMathOperator*{\argmax}{Arg\,max}
\newtheorem{lem}{Lema}
\newtheorem{prop}{Proposici\'on}
\newtheorem{cor}{Corolario}
\newtheorem{dem}{Demostración}
\numberwithin{equation}{subsection}
\numberwithin{definicion}{subsection}
\newtheorem{obs}{Observación}


%% Aquí se pueden definir nuevas abreviaturas para algunos comandos

\def\sen{{\rm sen\mspace{1.5mu}}}
\def\C{\mathbb C}
\def\R{\mathbb R}
\def\N{\mathbb N}
\def\Q{\mathbb Q}
\def\Z{\mathbb Z}
\def\V{\mathbb V}
\def\E{\mathbb E}
\def\to{\rightarrow}
\newcommand{\pb}{\mathbb{P}}



\newcommand{\ds}{\displaystyle}


%Para hacer normas en tex

\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\normm}[1]{\bigg\lVert#1\bigg\rVert}


%integrales bacanes
\usepackage{ esint }

%Para poner en negrita en modo matemático
\newcommand{\negri}{\boldsymbol}




\title{Simulación Estocástica}
\author{Clase 16}
\date{12 de septiembre de 2019}

\begin{document}
\maketitle

\subsection{Simulación de la distribución invariante}
Uno de los problemas en algoritmos MCMC. es la elección del número de veces en que debemos iterar la cadena de Markov. La diferencia con el método estándar de Monte Carlo es que la cadena parte de un punto arbitrario, esto es, la cadena no parte según su distribución de probabilidad invariante. En este sentido, uno podría pensar que existe una "fase inicial" del algoritmo, durante la cual la ley de la cadena toma valores cercanos a la distribución invariante. Entonces, durante la segunda fase del algoritmo, podríamos controlar la taza de convergencia en el teorema ergódico, lo cual se puede hacer con ayuda del teorema del límite central. \\ Asumiremos que $|E| < \infty$ y, para aligerar la notación $E=\{1,\cdots,N\}$.

\subsubsection{Simulación perfecta.}
La idea de MCMC. es simular  un $P$-CMH. $(X_n)_{n\in\N}$, donde  $P$ tiene a $\pi$ como probabilidad invariante, de modo que
\[\frac{1}{n}\sum_{k=1}^Nf(X_k) \approx \sum_{x\in E}f(x)\pi_x\]
El problema subyacente es que, a veces, se necesita tomar $n$ muy grande  para que lo anterior funcione, especialmente si $X_0$ tiene ley muy alejada de $\pi$.\\ \newline
Veremos, a continuación, una alternativa a MCMC, llamada \textit{simulación perfecta}. Obtendremos una simulación exacta de $\pi$ (e lugar de una aproximación como en MCMC) calzando una cantidad aleatoria de pasos.\\ \newline

Supondremos que $P$ cumple  
\begin{equation}
    \beta = \beta(P) = \sum_{y\in E}\inf_{y\in E}P_{xy} > 0
    \label{clase16_1}
\end{equation}
Gracias a las suposiciones que hicimos con respecto a $E$ (finito, $E=[N]$), \ref{clase16_1} es la condición de Doeblin $(D)$ con $n_0=1$. Notar que $\beta(P) \leq 1$.\\
Sea $\nu \in \mathcal{P}(E)$ dada por:
\[\nu_y := \frac{\inf_{x\in E}P_{xy}}{\beta},\hspace{0.2cm}y\in E,\]
\textbf{Observación: }Uno podría elegir otro par $(\beta,\nu)$, con $\beta >0$, y $\nu$ probabilidad sobre $E$ tal que $P_{xy}\geq \beta \nu_y$, pero la elección anterior es óptimo, en el sentido que maximiza $\beta$.\\ \newline
\textbf{Observación: }La afirmación $\beta(P)>0$ implica la existencia de una única clase recurrente, por lao tanto $P$ posee una única probabilidad invariante, a la que llamaremos $\pi$.\\ \newline

Sean los siguientes objetos independientes cada uno del otro, $\forall\,n\in\N$:
\begin{itemize}
    \item $\xi_n \sim Bernoulli(\beta)$
    \item $Z_n \sim \nu$
    \item $U_n \sim unif(0,1)$
\end{itemize}
Sea $Q$ la matriz Markoviana definida por
\[Q_{xy} = \frac{1}{1-\beta}(P_{xy}-\beta \nu_y),\]
y $f:E\times [0,1]\rightarrow E$, función de transición de $Q$, es decir: $\forall\,x\in E$, $\forall\,U\sim unif(0,1)$, se tiene que $f(x,U)\sim Q_{x\cdot}$.\\ \newline
Dado $X_0$, independiente de todo lo anterior, definamos $(X_n)_{n\in \N}$ mediante la recursión
\begin{equation}
    X_n = \xi_n Z_n + (1-\xi_n)f(X_{n-1},U_n)
    \label{clase16_2}
\end{equation}
\begin{prop}
\label{porp}
La recurrencia definida en \ref{clase16_2} es una $P$-C.M.
\end{prop}

\textbf{Demostración: }Condicionando a los valores de $\xi_n$ y ocupando probabilidades totales:
\[\prob(X_1 = y\,|\,X_0=x) = \prob_x(X_1=y)\]
\[= \prob_x(X_1=y\,|\,\xi = 1)\prob(\xi =1) + \prob_x(X_1=y\,|\,\xi=0)\prob(\xi=0)\]
\[ = \prob(Z = y)\prob(\xi = 1) + \prob_x(f(X_0,U)=y)\prob(\xi=0)\]
\[ = \nu_y\beta + \prob(f(x,U)=y)(1-\beta)\]
\[ = \nu_y \beta + Q_{xy}(1-\beta)\]
\[=\nu_y\beta + \frac{(P_{xy}-\beta \nu_y)}{(1-\beta)}(1-\beta)\]
\[= P_{xy}\]
Así probamos que la matriz de transición es $P$, falta por demostrar que $(X_n)_n$ es una cadena de Markov, es decir $\prob(X_n=y\,|\,X_{n-1}=x)=\prob(X_1=y\,|\,X_0=x)=P_{xy}\,\forall\,n\in\N$, resultado que es directo del Lema \ref{Lema 8}.\\
\rule{0.7em}{0.7em}\\ \newline
Tenemos lo siguiente:
\begin{prop}
Sea
\[T = \inf\{n\geq 1\,|\,\xi_n=1\}\]
Entonces $T\sim geom(\beta)$, $X_T \sim \nu$, además $X_T$ es independiete con $T$.
\end{prop}

\textbf{Demostración: }
\[\prob(X_T = x\,|\,T=n) = \prob(\xi_1 = 0,\cdots,\xi_{n-1}=0,\xi_n=1,Z_n=x)\]
\[ = (1-\beta)^{n-1}\beta \nu_x\]\\
\rule{0.7em}{0.7em}\\ \newline
La idea, ahora, es construir una $P$-C.M. estacionaria. Para construir $(X_n)_{n\in \Z}$, consideremos $(\xi_n)_{n\in \Z}$, $(Z_n)_{n\in \Z}$, $(U_n)_{n\in \Z}$, al igual que antes, y sea
\[\tau(n) = \max\{k\leq n:\,\xi_k=1\}\]
Para $n$ tal que  $\xi_n = 1$, se tiene que  $n=\tau(n)$ y definimos $X_n:=Z_n$.\\ Mientras que para $n$ tal que $\xi_n =0$, se tiene $\tau(n)<n$, y definimos iterativamente:
\[X_{\tau(n)+1}:= f(X_{\tau(n)},U_{\tau(n)+1})\]
\[X_{\tau(n)+2}:= f(X_{\tau(n)+1},U_{\tau(n)+2})\]
\[\cdot\]
\[\cdot\]
\[\cdot\]
\[X_n:= f(X_{n-1},U_n)\]
Básicamente, es la misma construcción  anterior, sólo que partiendo  con ley $\nu$ en el instante aleatorio $\tau(0)\leq 0$.\\ \newline
Notar que $-\tau(0)+1 \sim geom(\beta)$.
\begin{prop}
$(X_n)_{n\in \Z}$ es estacionario, es decir, $\forall\, l,k\in \Z$, $(X_{l+1},\cdots,X_{l+k}) \overset{\,d\,}{=}(X_1,\cdots,X_k)$.\\ En particular, $X_0\sim \pi$.
\end{prop}

\textbf{Demostración: }Sea $\mu = \mathcal{L}(X_0)$. Basta probar que $\mu P = \mu$.
\[\mu_x = \prob(X_0=x) = \sum_{k=0}^{\infty}\prob(X_0=x\,|\,\tau(0)=-k)\prob(\tau(0)=-k)\]
\[= \sum_{k=0}^{\infty}(\nu Q^k)_x (1-\beta)^{k}\beta\]
Como $P_{xy} = (1-\beta)Q_{xy} + \beta \nu_y$, tenemos
\[(\mu P)_y = \sum_{x\in E}\mu_x P_{xy} = \sum_{x\in E}\sum_{k=0}^{\infty}(\nu Q^k)_x(1-\beta)^k\beta P_{xy}\]
\[= \beta \sum_{k=0}^{\infty}(1-\beta)^{k+1}\sum_{x\in E}(\nu Q^k)_xQ_{xy} + \beta^2 \nu_y \sum_{k=0}^{\infty}(1-\beta)^k\sum_{x\in E}(\nu Q^k)_x\]
\[= \beta\sum_{k=0}^{\infty}(1-\beta)^{k+1}(\nu Q^{k+1})_y + \beta^2\nu_y\sum_{k=0}^{\infty}(1-\beta)^k\]
\[= \beta\sum_{k=1}^{\infty}(1-\beta)^{k}(\nu Q^{k})_y + \beta\]
\[= \beta\sum_{k=1}^{\infty}(1-\beta)^{k}(\nu Q^{k})_y + \beta(\nu Q^0)_y(1-\beta)^0\]
\[= \sum_{k=0}^{\infty}\beta(1-\beta)^{k}(\nu Q^{k})_y = \mu_y\]
\rule{0.7em}{0.7em}\\ \newline

\end{document}