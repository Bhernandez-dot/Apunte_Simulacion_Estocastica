\section{Teorema Central del Límite}
Nuestro objetivo es probar el primer teorema enunciado en este curso. Aquel que dice que a suma de variables aleatorias independientes, cuando se estandarizan, converge en ley a una distribución normal estándar. La demostración usual se basa en el uso de la función generadora de momentos. Sin embargo, ésta sólo existe cuando se garantiza la existencia de todos los momentos, para cada orden, por lo tanto, un resultado más general que sólo necesite varianza y esperanza finita requiere el uso de la función característica de la variable.\\ \newline
Los siguientes lemas son necesarios, previos a la demostración:

\begin{lem} Sea $X$, variable aleatoria en $\R$ tal que $\E(X^2) < +\infty$. Entonces:
\[\varphi_X(t) = 1 + it\,\E(X) - \frac{t^2}{2}\,\E(X^2) + o(t^2)\]
\end{lem}

\textbf{Demostración: } Usando la expasión de Taylor de la función $e^x$ y evaluarla en $ix$, tenemos que:
\[e^{ix} = 1 + ix - \frac{x^2}{2} + R_2(ix)\]
Donde $R_k$ es el \textit{resto integral} de la función $f(x)=e^x$:
\[R_k(ix) = \int_{0}^{ix}\frac{f^{(k)}(t)}{k!}(ix-t)^k dt = \int_{0}^{x}\frac{f^{(k)}(it)}{k!}(ix-it)^{k}dt = i^k \int_{0}^x\frac{f^{(k)}(it)}{k!}(x-t)^{k}dt\]
Basta tomar $k=2$ y $f^{(k)}(ix) = e^{ix}$ entonces:
\[\left|R_2(ix)\right| = \left|-\frac{1}{2}\int_{0}^x e^{it}(x-t)^2 dt\right| \leq \frac{1}{2}\int_{0}^{|x|}(|x|-t)^2 dt \leq \frac{|x|^3}{6}\]
Por otro lado, integrando por partes:
\[R_2(ix) = -\frac{1}{2}\int_{0}^x e^{it}(x-t)^2 dt = -\frac{1}{2}\left[\frac{e^{it}}{i}(x-t)^2\right|_{t=0}^{t=x} + 2\,\int_{0}^{x}\left \frac{e^{it}}{i}(x-t)dt\right]\]
\[\Rightarrow\,\left|R_2(ix)\right| \leq \frac{1}{2}\left[x^2 + 2\int_{0}^{|x|}(|x|-t)dt\right] = x^2\]
Así, obtenemos que:
\[\left|R_2(ix)\right| \leq \min\{x^2\,,\,\frac{|x|^3}{6}\}\]
Luego:
\[\varphi_X(t) = \E(e^{itX}) = \E\left(1+ itX - \frac{t^2}{2}X^2 + R_2(itX)\right)\]
\[= 1 + it\E(X) - \frac{t^2}{2}\E(X^2) + \E(R_2(itX))\]
Con esto, sólo basta probar que $\E(R_2(itX)) = o(t^2)$. Para esto necesitamos ver que \\$|R_2(itX)|/t^2 \, \xrightarrow{t\to 0}0$. En efecto:
\[\frac{\left|\E\left(R_2(itX)\right)\right|}{t^2}\leq \frac{\E\left(\min\{t^2X^2\,,\,\frac{t^3|X|^3}{6}\}\right)}{t^2}\]
\[\leq \E\left(\min\left\{X^2\,,\,\frac{t|X|^3}{6}\right\} \right) \]
Acá podemos notar que la esperanza está bién definida, puesto que el mínimo siempre es menor o igual a la variable $X^2$, cuya esperanza es finita. Sin embargo, a medida que $t\rightarrow 0$, el término $\frac{t|X|^3}{6}$ se irá acercando a cero, minorando a $X^2$ y arrastrándo la esperanza a cero vía el \textbf{T.C.D.}. Por lo tanto $\E(R_2(itX)) = o(t^2)$, concluyendo. \rule{0.7em}{0.7em} \\ \newline
\begin{lem} $\forall\,w_i\,,\,z_i\,\in\C$, tal que $|w_i|\leq 1$, $|z_i|\leq 1$ para todo $i=1,\cdots , n$. Se tiene que:
\[\left|\prod_{i=1}^{n}z_i\,-\,\prod_{i=1}^nw_i\right|\leq \sum_{i=1}^{n}|z_i-w_i|\]
\end{lem}
\textbf{Demostración: }
\[\left|\prod_{i=1}^nz_i\,-\,\prod_{i=1}^nw_i\right| = \left|\prod_{i=1}^nz_i\,-\,\prod_{i=1}^nw_i\,+\,w_n\prod_{i=1}^{n-1}z_i\,-\,w_n\prod_{i=1}^{n-1}z_i\right| = \left|(z_n-w_n)\prod_{i=1}^{n-1}z_i\,+\,w_n\left(\prod_{i=1}^{n-1}z_i\,-\,\prod_{i=1}^{n-1}w_i\right)\right|\]
\[\leq |z_n-w_n|\,\prod_{i=1}^{n-1}|z_i|\,+\,|w_n|\cdot\left|\prod_{i=1}^{n-1}z_i,-\,\prod_{i=1}^{n-1}w_i\right|\leq |z_n-w_n|\,+\,\left|\prod_{i=1}^{n-1}z_i,-\,\prod_{i=1}^{n-1}w_i\right|\]
De donde la última desigualdad sale del hecho de que, tanto los $w_i$ como los $z_i$ tenían módulo menor o igual a $1$. Finalmente, iterando este desarrollo $n$ veces, se concluye el resultado por inducción. \rule{0.7em}{0.7em}\\ \newline

Recordemos la manera en que se enunciaba el teorema central del límite.
\begin{teorema}[Teorema Central del Límite] Sean $X_1,X_2,\cdots$ variables aleatorias \textit{i.i.d.}, con $\E(X_1)=\mu\in\R$ y $Var(X_1)=\sigma^2<+\infty$. Entonces:
\[Z_n = \frac{1}{\sigma \sqrt{n}}\sum_{i=1}^{n}\left(X_i-\mu\right)\,\xrightarrow{\,\,\mathcal{L}\,\,}\,\mathcal{N}(0,1)\]
\end{teorema}
\subsection{Demostración del T.C.L.}
Sea $Z\sim \mathcal{N}(0,1)$, luego $\varphi_Z(t) = e^{\frac{-t^2}{2}}$. Por el teorema de continuidad de Lévy, basta probar que:
\[\varphi_{Z_n}(t)\xrightarrow{\,\,n\,\,}\varphi_Z(t)\hspace{1cm}\forall\,t\]
Sea $\varphi = \varphi_{\frac{X_i-\mu}{\sigma}}$, como $\frac{X_i-\mu}{\sigma}$ tiene ezperanza $0$ y varianza $1$, luego por el primer lema anterior:
\[\varphi(t) = 1-\frac{t^2}{2} + o(t^2)\]
Además: 
\[\varphi_{Z_n}(t) = \E(e^{it\frac{1}{\sqrt{n}}\sum_{i=1}^n\frac{X_i-\mu}{\sigma}}) \overset{i.i.d.}{=} \prod_{i=1}^n\E\left(e^{\frac{it}{\sqrt{n}}\left(\frac{X_i-\mu}{\sigma}\right)}\right)\]
\[ = \prod_{i=1}^n \varphi(\frac{t}{\sqrt{n}}) = \varphi(\frac{t}{\sqrt{n}})^n = \left(1-\frac{t^2}{2n}+o(\frac{t^2}{n})\right)^n\]
Con esto:
\[\left|\varphi_{Z_n}(t) - e^{-t^2/2}\right|\,\leq \left|\left(1-\frac{t^2}{2n}+o(\frac{t^2}{n})\right)^n\,-\,\left(1-\frac{t^2}{2n}\right)^n\right| + \left|\left(1-\frac{t^2}{2n}\right)^n\,-\,e^{-\frac{t^2}{2}}\right|\]
Usando el segundo lema, con $z_i = 1-\frac{t^2}{2n}+o(\frac{t^2}{n})$ y $w_i = 1-\frac{t^2}{2n}$, para todo $i$, tenemos que:
\[\left|\varphi_{Z_n}(t) - e^{-t^2/2}\right|\,\leq\,\sum_{i=1}^n\left|o(t^2/n)\right| \,+\, \left|\left(1-\frac{t^2}{2n}\right)^n\,-\,e^{-t^2/2}\right| = n|o(t^2/n)|\,+\,\left|\left(1-\frac{t^2}{2n}\right)^n\,-\,e^{-t^2/2}\right|\]
\[\leq\,\frac{|o(t^2/n)|}{\frac{1}{n}}\,+\,\left|\left(1-\frac{t^2}{2n}\right)^n\,-\,e^{-t^2/2}\right|\,\rightarrow\,0\]
Donde el segundo sumando conerge a 0 por la definición de límite de la función exponencial\footnote{Además queda como propuesto mostrar que cuando $n$ tiende a infinito, para cualquier $t$, el primer sumando converge a 0, utilizando la definición de la función $o(t^2/n)$.}. Con esto demostramos que $\varphi_{Z_n}$ converge a esa exponencial, que es justamente la función característica de la variable normal estándar. \rule{0.7em}{0.7em}